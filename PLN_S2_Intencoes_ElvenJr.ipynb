{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhVcKWi7QLeFpSvnH2jX6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elvenjr/PLN-SC-2025-1-Proj-G10/blob/main/PLN_S2_Intencoes_ElvenJr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Clona o seu repositório pessoal\n",
        "!git clone https://github.com/elvenjr/PLN-SC-2025-1-Proj-G10.git\n",
        "\n",
        "# 2) Entra na pasta clonada\n",
        "%cd PLN-SC-2025-1-Proj-G10\n",
        "\n",
        "# 3) Cria as pastas que ainda não existem\n",
        "!mkdir -p dataset src results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmW2V7GInB6h",
        "outputId": "b665b7a2-b234-4cda-a69b-2f28e86fd31c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PLN-SC-2025-1-Proj-G10'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n",
            "/content/PLN-SC-2025-1-Proj-G10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Dataset"
      ],
      "metadata": {
        "id": "g4pwWE9_nx3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > dataset/intent_dataset.csv\n",
        "text,intent\n",
        "\"Olá, bom dia!\",\"saudacao\"\n",
        "\"Oi, tudo bem?\",\"saudacao\"\n",
        "\"Bom dia, como posso falar com vocês?\",\"saudacao\"\n",
        "\"Boa tarde!\",\"saudacao\"\n",
        "\"Boa noite, preciso de ajuda\",\"saudacao\"\n",
        "\"Olá, gostaria de atendimento\",\"saudacao\"\n",
        "\"Oi, alguém pode me ajudar?\",\"saudacao\"\n",
        "\"Bom dia, estou precisando de suporte\",\"saudacao\"\n",
        "\"Olá pessoal!\",\"saudacao\"\n",
        "\"Oi, como vai?\",\"saudacao\"\n",
        "\"Bom dia, tudo certo?\",\"saudacao\"\n",
        "\"Boa tarde, podem me atender?\",\"saudacao\"\n",
        "\"Olá, preciso falar com alguém\",\"saudacao\"\n",
        "\"Oi galera!\",\"saudacao\"\n",
        "\"Bom dia a todos\",\"saudacao\"\n",
        "\"Boa noite, estão aí?\",\"saudacao\"\n",
        "\"Olá, vocês estão online?\",\"saudacao\"\n",
        "\"Oi, tem alguém disponível?\",\"saudacao\"\n",
        "\"Bom dia, quero falar com o suporte\",\"saudacao\"\n",
        "\"Olá, estou entrando em contato\",\"saudacao\"\n",
        "\"Quero saber mais sobre o produto X\",\"solicitar_info_produto\"\n",
        "\"Podem me informar sobre os planos disponíveis?\",\"solicitar_info_produto\"\n",
        "\"Qual o preço do serviço premium?\",\"solicitar_info_produto\"\n",
        "\"Gostaria de informações sobre a assinatura\",\"solicitar_info_produto\"\n",
        "\"Quais são as funcionalidades do plano básico?\",\"solicitar_info_produto\"\n",
        "\"Quanto custa o produto Y?\",\"solicitar_info_produto\"\n",
        "\"Quero saber os valores dos pacotes\",\"solicitar_info_produto\"\n",
        "\"Me explica como funciona o serviço?\",\"solicitar_info_produto\"\n",
        "\"Quais produtos vocês oferecem?\",\"solicitar_info_produto\"\n",
        "\"Preciso de informações sobre preços\",\"solicitar_info_produto\"\n",
        "\"O que está incluído no plano gold?\",\"solicitar_info_produto\"\n",
        "\"Vocês têm promoções ativas?\",\"solicitar_info_produto\"\n",
        "\"Qual a diferença entre os planos?\",\"solicitar_info_produto\"\n",
        "\"Gostaria de conhecer os serviços\",\"solicitar_info_produto\"\n",
        "\"Me manda a tabela de preços?\",\"solicitar_info_produto\"\n",
        "\"Quero saber sobre as formas de pagamento\",\"solicitar_info_produto\"\n",
        "\"Tem desconto para pagamento à vista?\",\"solicitar_info_produto\"\n",
        "\"Quais são os benefícios do plano anual?\",\"solicitar_info_produto\"\n",
        "\"Vocês parcelam em quantas vezes?\",\"solicitar_info_produto\"\n",
        "\"O que vem incluído na mensalidade?\",\"solicitar_info_produto\"\n",
        "\"Estou muito insatisfeito com o atendimento!\",\"reclamar_servico\"\n",
        "\"O serviço não está funcionando há 3 dias\",\"reclamar_servico\"\n",
        "\"Vocês não resolveram meu problema\",\"reclamar_servico\"\n",
        "\"Péssimo atendimento que recebi ontem\",\"reclamar_servico\"\n",
        "\"O produto veio com defeito\",\"reclamar_servico\"\n",
        "\"Estou há horas esperando uma resposta\",\"reclamar_servico\"\n",
        "\"Isso é um absurdo, quero falar com o gerente\",\"reclamar_servico\"\n",
        "\"O sistema está fora do ar novamente\",\"reclamar_servico\"\n",
        "\"Não consigo acessar minha conta\",\"reclamar_servico\"\n",
        "\"O suporte não resolve nada\",\"reclamar_servico\"\n",
        "\"Já é a terceira vez que tenho esse problema\",\"reclamar_servico\"\n",
        "\"Vocês não cumprem o que prometem\",\"reclamar_servico\"\n",
        "\"Estou decepcionado com a empresa\",\"reclamar_servico\"\n",
        "\"O serviço está péssimo ultimamente\",\"reclamar_servico\"\n",
        "\"Ninguém resolve meu caso\",\"reclamar_servico\"\n",
        "\"Quero registrar uma reclamação formal\",\"reclamar_servico\"\n",
        "\"O atendente foi muito mal educado\",\"reclamar_servico\"\n",
        "\"Não recebi o que comprei\",\"reclamar_servico\"\n",
        "\"O prazo de entrega não foi cumprido\",\"reclamar_servico\"\n",
        "\"Estou esperando uma solução há semanas\",\"reclamar_servico\"\n",
        "\"Muito obrigado pela ajuda!\",\"agradecer\"\n",
        "\"Obrigado, resolveram meu problema\",\"agradecer\"\n",
        "\"Agradeço o excelente atendimento\",\"agradecer\"\n",
        "\"Valeu pela atenção!\",\"agradecer\"\n",
        "\"Obrigado por esclarecer minhas dúvidas\",\"agradecer\"\n",
        "\"Vocês foram muito atenciosos, obrigado\",\"agradecer\"\n",
        "\"Gratidão pelo suporte rápido\",\"agradecer\"\n",
        "\"Muito obrigado pela paciência\",\"agradecer\"\n",
        "\"Agradeço a rapidez no atendimento\",\"agradecer\"\n",
        "\"Obrigado, foi muito útil\",\"agradecer\"\n",
        "\"Excelente trabalho, obrigado!\",\"agradecer\"\n",
        "\"Agradeço pela solução apresentada\",\"agradecer\"\n",
        "\"Muito grato pela ajuda\",\"agradecer\"\n",
        "\"Obrigado por resolver tão rápido\",\"agradecer\"\n",
        "\"Vocês são ótimos, obrigado!\",\"agradecer\"\n",
        "\"Agradeço o profissionalismo\",\"agradecer\"\n",
        "\"Obrigado pela compreensão\",\"agradecer\"\n",
        "\"Valeu mesmo pela força!\",\"agradecer\"\n",
        "\"Muito obrigado, vocês salvaram meu dia\",\"agradecer\"\n",
        "\"Gratidão por toda assistência\",\"agradecer\"\n",
        "\"Tchau, até mais!\",\"despedida\"\n",
        "\"Até logo, obrigado\",\"despedida\"\n",
        "\"Fico por aqui, abraços\",\"despedida\"\n",
        "\"Até a próxima!\",\"despedida\"\n",
        "\"Tchau pessoal!\",\"despedida\"\n",
        "\"Por hoje é só, até mais\",\"despedida\"\n",
        "\"Vou ficando por aqui, obrigado\",\"despedida\"\n",
        "\"Até breve!\",\"despedida\"\n",
        "\"Falou, valeu!\",\"despedida\"\n",
        "\"Era isso, tchau!\",\"despedida\"\n",
        "\"Até mais ver!\",\"despedida\"\n",
        "\"Encerrando por aqui, abraços\",\"despedida\"\n",
        "\"Até outro dia!\",\"despedida\"\n",
        "\"Por enquanto é só, tchau\",\"despedida\"\n",
        "\"Abraços e até logo!\",\"despedida\"\n",
        "\"Vou nessa, até mais\",\"despedida\"\n",
        "\"Fim do atendimento, obrigado e tchau\",\"despedida\"\n",
        "\"Até qualquer hora!\",\"despedida\"\n",
        "\"Era só isso mesmo, tchau\",\"despedida\"\n",
        "\"Beleza então, até mais!\",\"despedida\"\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "PNWva4wEnCYh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('dataset/intent_dataset.csv')\n",
        "print(\"Linhas totais:\", len(df))\n",
        "print(\"Faltando texto:\", df['text'].isna().sum())\n",
        "print(\"Faltando intent:\", df['intent'].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRXBL2GvnmDM",
        "outputId": "c70daf55-a218-4107-e505-41425f0e1e6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas totais: 100\n",
            "Faltando texto: 0\n",
            "Faltando intent: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classificador"
      ],
      "metadata": {
        "id": "R_upNODNn55v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > src/intent_classifier.py\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import nltk, os, json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "\n",
        "class IntentClassifier:\n",
        "    def __init__(self):\n",
        "        self.stopwords_pt = set(stopwords.words('portuguese'))\n",
        "        self.stemmer = RSLPStemmer()\n",
        "        self.tfidf = TfidfVectorizer(max_features=500)\n",
        "        self.classifier = MultinomialNB()\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        tokens = nltk.word_tokenize(text.lower(), language='portuguese')\n",
        "        tokens = [self.stemmer.stem(t) for t in tokens if t.isalpha() and t not in self.stopwords_pt]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_vec = self.tfidf.fit_transform(X)\n",
        "        self.classifier.fit(X_vec, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.classifier.predict(self.tfidf.transform(X))\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "        return (\n",
        "            classification_report(y_true, y_pred, output_dict=True),\n",
        "            confusion_matrix(y_true, y_pred, labels=self.classifier.classes_),\n",
        "            accuracy_score(y_true, y_pred)\n",
        "        )\n",
        "\n",
        "def main():\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    df = pd.read_csv('dataset/intent_dataset.csv')\n",
        "    clf = IntentClassifier()\n",
        "    df['clean'] = df['text'].apply(clf.preprocess)\n",
        "\n",
        "    Xtr, Xte, ytr, yte = train_test_split(\n",
        "        df['clean'], df['intent'], test_size=0.2, random_state=42, stratify=df['intent']\n",
        "    )\n",
        "    clf.train(Xtr, ytr)\n",
        "    ypred = clf.predict(Xte)\n",
        "    report, cm, acc = clf.evaluate(yte, ypred)\n",
        "\n",
        "    with open('results/metrics.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d',\n",
        "                xticklabels=clf.classifier.classes_,\n",
        "                yticklabels=clf.classifier.classes_)\n",
        "    plt.savefig('results/confusion_matrix.png', dpi=300)\n",
        "    print(f\"ACURÁCIA: {acc:.2%}\")\n",
        "    print(classification_report(yte, ypred))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "EOF\n",
        "chmod +x src/intent_classifier.py\n"
      ],
      "metadata": {
        "id": "HWrabQPTnm6G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependências e Executar"
      ],
      "metadata": {
        "id": "zRxYa95BoF1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas==2.2.2 scikit-learn==1.5.0 nltk==3.8.1 seaborn==0.13.2 matplotlib==3.9.0\n",
        "!python src/intent_classifier.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imKsauwan76E",
        "outputId": "f9473c00-9f73-412f-bb6d-a979946a8f5a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACURÁCIA: 70.00%\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "             agradecer       0.57      1.00      0.73         4\n",
            "             despedida       1.00      0.50      0.67         4\n",
            "      reclamar_servico       0.33      0.25      0.29         4\n",
            "              saudacao       0.80      1.00      0.89         4\n",
            "solicitar_info_produto       1.00      0.75      0.86         4\n",
            "\n",
            "              accuracy                           0.70        20\n",
            "             macro avg       0.74      0.70      0.69        20\n",
            "          weighted avg       0.74      0.70      0.69        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurácia geral (70 %): de 20 exemplos de teste, 14 foram classificados corretamente.\n",
        "\n",
        "Classes com melhor desempenho:\n",
        "\n",
        "saudacao e solicitar_info_produto alcançaram F1 ≥ 0.86, indicando padrão de linguagem bem distinto.\n",
        "\n",
        "Pontos fracos:\n",
        "\n",
        "reclamar_servico obteve recall=0.25 e F1=0.29, ou seja, o modelo só identificou corretamente 1 em cada 4 reclamações.\n",
        "\n",
        "despedida teve recall=0.50, perdendo metade dos exemplos.\n",
        "\n",
        "5.2 Por que reclamar_servico foi tão baixo?\n",
        "Vocabulário compartilhado\n",
        "Muitas reclamações usam expressões semelhantes a pedidos de informação (“quero falar com o gerente” vs “quero saber preços”), confundindo o TF-IDF + Naive Bayes.\n",
        "\n",
        "Dataset pequeno\n",
        "Apenas 20 exemplos de reclamação: com tão poucos casos, o modelo não aprendeu bem as palavras-chave de insatisfação."
      ],
      "metadata": {
        "id": "iBzUtUgfzWmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentar dados da classe reclamar_servico\n",
        "Frases que expressem insatisfação em diversos estilos."
      ],
      "metadata": {
        "id": "Ov0EoOB11BFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' >> dataset/intent_dataset.csv\n",
        "\"Não estou nada satisfeito com o suporte\",\"reclamar_servico\"\n",
        "\"Minha experiência está sendo frustrante\",\"reclamar_servico\"\n",
        "\"Cadê a resposta para minha solicitação?\",\"reclamar_servico\"\n",
        "\"O atendimento é muito lento\",\"reclamar_servico\"\n",
        "\"Problema recorrente e ninguém resolve\",\"reclamar_servico\"\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "x75rtMggoJ7S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhorar o vetor TF-IDF\n",
        "N-gramas para capturar frases curtas e expressões compostas que são comuns em reclamações e despedidas:"
      ],
      "metadata": {
        "id": "_6yzgFO_1Kw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > src/intent_classifier.py\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import nltk, os, json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "\n",
        "class IntentClassifier:\n",
        "    def __init__(self):\n",
        "        self.stopwords_pt = set(stopwords.words('portuguese'))\n",
        "        self.stemmer = RSLPStemmer()\n",
        "        self.tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
        "        self.classifier = MultinomialNB()\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        tokens = nltk.word_tokenize(text.lower(), language='portuguese')\n",
        "        tokens = [self.stemmer.stem(t) for t in tokens if t.isalpha() and t not in self.stopwords_pt]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_vec = self.tfidf.fit_transform(X)\n",
        "        self.classifier.fit(X_vec, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.classifier.predict(self.tfidf.transform(X))\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "        return (\n",
        "            classification_report(y_true, y_pred, output_dict=True),\n",
        "            confusion_matrix(y_true, y_pred, labels=self.classifier.classes_),\n",
        "            accuracy_score(y_true, y_pred)\n",
        "        )\n",
        "\n",
        "def main():\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    df = pd.read_csv('dataset/intent_dataset.csv')\n",
        "    clf = IntentClassifier()\n",
        "    df['clean'] = df['text'].apply(clf.preprocess)\n",
        "\n",
        "    Xtr, Xte, ytr, yte = train_test_split(\n",
        "        df['clean'], df['intent'], test_size=0.2, random_state=42, stratify=df['intent']\n",
        "    )\n",
        "    clf.train(Xtr, ytr)\n",
        "    ypred = clf.predict(Xte)\n",
        "    report, cm, acc = clf.evaluate(yte, ypred)\n",
        "\n",
        "    with open('results/metrics.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d',\n",
        "                xticklabels=clf.classifier.classes_,\n",
        "                yticklabels=clf.classifier.classes_)\n",
        "    plt.savefig('results/confusion_matrix.png', dpi=300)\n",
        "    print(f\"ACURÁCIA: {acc:.2%}\")\n",
        "    print(classification_report(yte, ypred))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "EOF\n",
        "chmod +x src/intent_classifier.py\n"
      ],
      "metadata": {
        "id": "5NHtlviz1HuD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas==2.2.2 scikit-learn==1.5.0 nltk==3.8.1 seaborn==0.13.2 matplotlib==3.9.0\n",
        "!python src/intent_classifier.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGYIh9fO2FO3",
        "outputId": "f321c35d-ecd4-4024-cb1e-fa7a91755b28"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACURÁCIA: 80.95%\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "             agradecer       0.80      1.00      0.89         4\n",
            "             despedida       1.00      0.50      0.67         4\n",
            "      reclamar_servico       0.75      0.60      0.67         5\n",
            "              saudacao       0.80      1.00      0.89         4\n",
            "solicitar_info_produto       0.80      1.00      0.89         4\n",
            "\n",
            "              accuracy                           0.81        21\n",
            "             macro avg       0.83      0.82      0.80        21\n",
            "          weighted avg       0.83      0.81      0.79        21\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKCFAQdA5gvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}